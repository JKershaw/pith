# Benchmark Plan: 2025-12-31

## Repository

- **Target**: Pith (self-test)
- **Path**: /home/user/pith
- **Commit**: e76b9a8
- **Size**: 15 source files, ~6k lines

## Scope

- **Tasks**: All 15 tasks from the task bank (3 per category)
- **Categories**:
  - A1-A3: Architecture tasks
  - B1-B3: Specific behavior tasks
  - R1-R3: Cross-module relationship tasks
  - D1-D3: Debugging/investigation tasks
  - M1-M3: Modification planning tasks

## Expected Duration

- Extraction: ~10s
- Build: ~3s
- Generation: ~3-5 min (depends on LLM response times)
- Evaluation: ~30-45 min (15 tasks x 2 approaches x scoring)
- **Total**: ~45-60 minutes

## Cost Estimate

- Generation: ~$0.50-1.00 (using qwen/qwen-turbo or configured model)
- Evaluation: Minimal (using local exploration agents)

## Methodology

1. Run full Pith pipeline (extract -> build -> generate)
2. For each of 15 tasks:
   - Query Pith for relevant context
   - Run Control agent to explore codebase directly
   - Score both on 5 criteria (Relevance, Completeness, Accuracy, Efficiency, Actionability)
3. Compile results with comparison to v7 benchmark (2025-12-30)

## Success Criteria

- All 15 tasks evaluated
- Results documented in standard format
- Comparison with previous benchmark included
