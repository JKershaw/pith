# Benchmark Run: 2025-12-31 (Self-Test v3)

## Configuration

- **Repository**: Pith (self-test)
- **Size**: 43 files extracted, ~18k lines (source only)
- **Pith version**: 9dd37d1
- **Model**: qwen/qwen-turbo
- **Tasks**: 15 (3 per category, full task bank)

## Pipeline Metrics

| Stage      | Time             | Notes                                               |
| ---------- | ---------------- | --------------------------------------------------- |
| Extraction | 13.9s            | 43 files extracted                                  |
| Build      | 4.0s             | 151 nodes created (43 file, 98 function, 10 module) |
| Generation | 236s (~4 min)    | 53 nodes with prose (files + modules)               |
| **Total**  | ~254s (~4.2 min) | Full pipeline with prose                            |

- Nodes created: 43 file, 98 function, 10 module (151 total)
- Nodes with prose: 53 (files + modules)
- Estimated cost: ~$0.50-1.00 (qwen-turbo)

---

## Task Results

### Architecture Tasks (A1-A3)

#### A1: Main Components

**Question**: "What are the main components of this codebase and how do they interact?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 3/5       | 5/5       |
| Efficiency    | 3/5       | 5/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **16/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 32,033 | **Control tokens**: 23,692
**Notes**: Control found all components (api, builder, cli, config, db, errors, extractor, generator). Pith missed critical modules (extractor, db) and fuzzy matching created misleading connections.

---

#### A2: Data Flow

**Question**: "Explain the data flow from file input to wiki output."

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **16/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 20,518 | **Control tokens**: 6,625
**Notes**: Control was 3x more token-efficient and provided complete coverage of all three phases. Pith's fuzzy matching caused it to miss the extraction phase entirely.

---

#### A3: Design Patterns

**Question**: "What design patterns are used in this codebase?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 5/5       | 5/5       |
| Completeness  | 4/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 3/5       | 5/5       |
| Actionability | 5/5       | 4/5       |
| **Total**     | **22/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 42,400 | **Control tokens**: 13,710
**Notes**: Pith provided pre-computed pattern detection but 3x more tokens. Control found all patterns plus additional ones (Factory, Strategy, Visitor) with 68% fewer tokens.

---

### Specific Behavior Tasks (B1-B3)

#### B1: Extraction Cache

**Question**: "How does the extraction cache determine if a file needs re-extraction?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 5/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 4/5       | 5/5       |
| **Total**     | **19/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 17,891 | **Control tokens**: 3,225
**Notes**: Control is 5.5x more token-efficient. Pith's context query fuzzy-matched to wrong file, adding irrelevant content.

---

#### B2: buildPrompt Function

**Question**: "How does buildPrompt construct LLM prompts for different node types?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 2/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **12/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 13,579 | **Control tokens**: 8,605
**Notes**: Pith returned extensive but mostly irrelevant context about builder/extractor modules while missing the actual prompt templates. Control found complete implementations with 37% lower token cost.

---

#### B3: LLM Retry Logic

**Question**: "What is the retry logic in the LLM client and what triggers a retry?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 5/5       | 5/5       |
| Completeness  | 5/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 3/5       | 4/5       |
| Actionability | 5/5       | 5/5       |
| **Total**     | **23/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 13,248 | **Control tokens**: 7,528
**Notes**: Both provided complete and accurate information. Control won by being 43% more token-efficient while providing the same accuracy and completeness.

---

### Relationship Tasks (R1-R3)

#### R1: WikiNode Impact

**Question**: "What files would be affected if I changed the WikiNode interface?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 5/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 4/5       | 5/5       |
| **Total**     | **20/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 21,579 | **Control tokens**: 1,854
**Notes**: Pith returned 11.6x more data with only ~0.5% relevant (importedBy edges). Control retrieved exactly what was needed with 91% fewer tokens.

---

#### R2: API to Database

**Question**: "How do the API routes connect to the database layer?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 4/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **17/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 18,009 | **Control tokens**: 16,119
**Notes**: Control provided more focused, directly relevant information by reading only the 3 essential files. Pith included 10 nodes with extensive prose that diluted the core answer.

---

#### R3: extractFile Consumers

**Question**: "What are all the consumers of the extractFile function?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 1/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **12/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 19,812 | **Control tokens**: 2,000
**Notes**: Pith provided file-level import edges but no function-level cross-file call tracking. Control with Grep found all 51 call sites across 4 files with precise line numbers, using 10x fewer tokens.

---

### Debugging Tasks (D1-D3)

#### D1: Empty Prose

**Question**: "Generation completes but some nodes have empty prose. What should I investigate?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **15/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 13,260 | **Control tokens**: 9,778
**Notes**: Control identified exact error handling locations. Pith returned comprehensive but unfocused context including unrelated builder and AST extraction details.

---

#### D2: Slow Generation

**Question**: "Why might the generate command be slow?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 4/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **17/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 24,399 | **Control tokens**: 14,766
**Notes**: Control used 40% fewer tokens while identifying the key issue: extract uses BATCH_SIZE=4 but generate processes sequentially. Pith missed this comparative insight.

---

#### D3: 404 for Existing File

**Question**: "API returns 404 for a file that exists. What could cause this?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 2/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **13/25** | **24/25** |

**Winner**: Control
**Pith tokens**: 21,251 | **Control tokens**: 12,619
**Notes**: Control provided the actual route handling logic explaining all three 404 scenarios. Pith returned rich metadata about the API file itself but didn't explain the 404 logic.

---

### Modification Tasks (M1-M3)

#### M1: JavaScript Support

**Question**: "How would I add support for JavaScript (.js) files in addition to TypeScript?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 2/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 3/5       | 5/5       |
| Efficiency    | 1/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **10/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 27,647 | **Control tokens**: 6,250
**Notes**: Control identified all 6 locations where .ts extension logic exists. Pith returned 4.4x more tokens with mostly irrelevant content and fuzzy-matched to wrong file.

---

#### M2: Rate Limiting

**Question**: "How would I add rate limiting to the API endpoints?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 4/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 4/5       | 4/5       |
| **Total**     | **18/25** | **23/25** |

**Winner**: Control
**Pith tokens**: 16,275 | **Control tokens**: 10,562
**Notes**: Control wins with 35% fewer tokens and better relevance. Pith included extensive but tangential details (fuzzy matching algorithms, builder internals, test implementations).

---

#### M3: Add Complexity Field

**Question**: "I want to add a 'complexity' field to WikiNode. What files need changes?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **14/25** | **25/25** |

**Winner**: Control
**Pith tokens**: 21,579 | **Control tokens**: 3,300
**Notes**: Control was 6.5x more efficient and far more actionable. Pith showed all importedBy files but couldn't distinguish which need changes.

---

## Summary

### Overall Scores

| Metric            | Pith                | Control             |
| ----------------- | ------------------- | ------------------- |
| **Average score** | **16.3/25 (65.2%)** | **24.5/25 (98.0%)** |
| Win/Loss/Tie      | 0-15-0              | 15-0-0              |

### Score Breakdown by Category

| Category             | Pith Avg | Control Avg | Gap   |
| -------------------- | -------- | ----------- | ----- |
| Architecture (A1-A3) | 18.0     | 24.7        | -6.7  |
| Behavior (B1-B3)     | 18.0     | 24.3        | -6.3  |
| Relationship (R1-R3) | 16.3     | 24.7        | -8.4  |
| Debugging (D1-D3)    | 15.0     | 24.0        | -9.0  |
| Modification (M1-M3) | 14.0     | 24.3        | -10.3 |

### Score Breakdown by Criterion

| Criterion     | Pith Avg | Control Avg | Gap  |
| ------------- | -------- | ----------- | ---- |
| Relevance     | 3.3      | 5.0         | -1.7 |
| Completeness  | 3.4      | 4.9         | -1.5 |
| Accuracy      | 4.4      | 5.0         | -0.6 |
| Efficiency    | 2.1      | 4.7         | -2.6 |
| Actionability | 3.1      | 4.9         | -1.8 |

### Token Usage Comparison

| Metric              | Pith    | Control | Ratio |
| ------------------- | ------- | ------- | ----- |
| Total tokens        | 323,480 | 140,143 | 2.3x  |
| Average per task    | 21,565  | 9,343   | 2.3x  |
| Most efficient task | 13,248  | 1,854   | R1    |
| Least efficient     | 42,400  | 23,692  | A1    |

### Comparison to Previous Benchmarks

| Metric          | v1 (2025-12-31) | v2 (2025-12-31) | This Run (v3) | Change from v2 |
| --------------- | --------------- | --------------- | ------------- | -------------- |
| Pith Average    | 19.4/25 (78%)   | 16.8/25 (67%)   | 16.3/25 (65%) | -2%            |
| Control Average | 22.9/25 (92%)   | 23.3/25 (93%)   | 24.5/25 (98%) | +5%            |
| Gap             | -3.5 points     | -6.5 points     | -8.2 points   | -1.7           |
| Pith Win Rate   | 5-9-1           | 1-13-1          | 0-15-0        | -1 win         |

---

## Information Gap Analysis

### Critical Issues Identified

| Issue                          | Impact   | Examples                                                          |
| ------------------------------ | -------- | ----------------------------------------------------------------- |
| **Fuzzy matching errors**      | Critical | A1, A2, B1, M1: API matched wrong files (extractor->generator)    |
| **Token inefficiency**         | Critical | All tasks: 2.3x more tokens on average                            |
| **File-level vs symbol-level** | High     | R3: importedBy shows 13 files but only 4 actually use extractFile |
| **Missing cross-file context** | High     | R2, D2: Didn't show critical initialization flows                 |

### Information Type Comparison

| Information Type       |  Pith   | Control | Gap Severity |
| ---------------------- | :-----: | :-----: | :----------: |
| Module/file names      |   Yes   |   Yes   |     None     |
| One-line summary       |   Yes   | Partial |     None     |
| Purpose description    |   Yes   | Partial |     None     |
| Gotchas/warnings       |   Yes   |   No    |    Minor     |
| Import relationships   |   Yes   |   Yes   |     None     |
| Fan-in/fan-out metrics |   Yes   |   No    |    Minor     |
| Line numbers           | Partial |   Yes   |    Medium    |
| Code snippets          | Partial |   Yes   |     High     |
| Function signatures    |   Yes   |   Yes   |     None     |
| Implementation details |   No    |   Yes   |   Critical   |
| Cross-file flows       |   No    |   Yes   |     High     |
| Symbol-level tracking  |   No    |   Yes   |     High     |
| Targeted searches      |   No    |   Yes   |   Critical   |

---

## Key Conclusions

### 1. Control Dominance

- **Control won all 15 tasks** (vs 13 in v2, 9 in v1)
- Average gap widened: 6.5 -> 8.2 points
- Control now at 98% average score vs Pith's 65%

### 2. Root Causes of Pith Underperformance

1. **Fuzzy matching failures**: Queries for src/extractor matched src/generator
2. **Token bloat**: Returns entire file documentation regardless of query focus
3. **File-level granularity**: Cannot identify specific symbol consumers
4. **Missing implementation details**: Prose summaries lack actionable code context

### 3. Control's Consistent Strengths

- Targeted searches with grep/glob (10x efficiency on R3)
- Symbol-level precision
- Cross-file flow tracing
- Direct access to implementation details

### 4. Pith's Remaining Strengths

- Pre-computed dependency graphs (importedBy edges)
- Structured metadata (fanIn/fanOut, git history)
- High accuracy when context is found (4.4/5)
- Gotchas and warnings from prose generation

---

## Recommendations

### For Pith Development (Priority Order)

1. **Critical - Fix fuzzy matching**: Stricter thresholds or exact-match fallback
2. **Critical - Response sizing**: Return excerpts, not full files
3. **Critical - Query routing**: Better file path resolution
4. **High - Symbol tracking**: Track function/type consumers, not just file imports
5. **High - Cross-file flows**: Include related files in context bundles
6. **Medium - Implementation snippets**: Include relevant code, not just summaries

### For Benchmark Methodology

1. Track fuzzy matching accuracy as a separate metric
2. Measure token efficiency ratio per task
3. Test path resolution edge cases

---

## Revision History

| Date       | Change           | Author |
| ---------- | ---------------- | ------ |
| 2025-12-31 | v3 benchmark run | Claude |
