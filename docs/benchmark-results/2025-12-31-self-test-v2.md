# Benchmark Run: 2025-12-31-v2 (Self-Test)

## Configuration

- **Repository**: Pith (self-test)
- **Size**: 41 files extracted, ~17k lines (source only)
- **Pith version**: ede898f
- **Model**: qwen/qwen-turbo
- **Tasks**: 15 (3 per category, full task bank)

## Pipeline Metrics

| Stage      | Time             | Notes                                               |
| ---------- | ---------------- | --------------------------------------------------- |
| Extraction | 15.9s            | 41 files extracted                                  |
| Build      | 6.0s             | 144 nodes created (41 file, 93 function, 10 module) |
| Generation | 229.3s           | 51 nodes with prose (files + modules)               |
| **Total**  | ~251s (~4.2 min) | Full pipeline with prose                            |

- Nodes created: 41 file, 93 function, 10 module (144 total)
- Nodes with prose: 51 (files + modules)
- Estimated cost: ~$0.50-1.00 (qwen-turbo)

---

## Task Results

### Architecture Tasks (A1-A3)

#### A1: Main Components

**Question**: "What are the main components of this codebase and how do they interact?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 5/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 5/5       | 4/5       |
| **Total**     | **21/25** | **23/25** |

**Winner**: Control
**Notes**: Control wins narrowly due to efficiency (23 vs 21). Pith provided excellent comprehensive documentation (26K tokens) but was over-engineered for an architecture question - included extensive function-level details not needed. Control (12K tokens) efficiently captured the essential architecture.

---

#### A2: Data Flow

**Question**: "Explain the data flow from file input to wiki output."

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 1/5       | 5/5       |
| Completeness  | 1/5       | 5/5       |
| Accuracy      | 3/5       | 5/5       |
| Efficiency    | 4/5       | 3/5       |
| Actionability | 1/5       | 5/5       |
| **Total**     | **10/25** | **23/25** |

**Winner**: Control
**Notes**: Pith API failed - 3 of 4 requested files returned "Node not found" (wrong paths: src/extract vs src/extractor). Control successfully traced the complete flow.

---

#### A3: Design Patterns

**Question**: "What design patterns are used in this codebase?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 2/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 4/5       | 5/5       |
| Efficiency    | 4/5       | 3/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **15/25** | **23/25** |

**Winner**: Control
**Notes**: Pith API failed to find 4 of 5 requested files. Control identified 15+ design patterns across architectural, creational, structural, and behavioral categories with specific file locations.

---

### Specific Behavior Tasks (B1-B3)

#### B1: Extraction Cache

**Question**: "How does the extraction cache determine if a file needs re-extraction?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 5/5       | 5/5       |
| Completeness  | 5/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 3/5       | 5/5       |
| Actionability | 5/5       | 4/5       |
| **Total**     | **23/25** | **23/25** |

**Winner**: Tie
**Notes**: Both scored 23/25 with different strengths. Pith excelled in completeness and actionability. Control excelled in efficiency (30% fewer tokens).

---

#### B2: buildPrompt Function

**Question**: "How does buildPrompt construct LLM prompts for different node types?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 4/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **17/25** | **25/25** |

**Winner**: Control
**Notes**: Control wins decisively (25 vs 17). Pith provided 8x more tokens but included 20+ unrelated functions and truncated prompt templates. Control delivered focused, complete templates.

---

#### B3: LLM Retry Logic

**Question**: "What is the retry logic in the LLM client and what triggers a retry?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 5/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **18/25** | **25/25** |

**Winner**: Control
**Notes**: Pith provided complete info but with 8x more tokens than needed. Control extracted only retry-related code (maxRetries=3, timeout=30s, conditions).

---

### Relationship Tasks (R1-R3)

#### R1: WikiNode Impact

**Question**: "What files would be affected if I changed the WikiNode interface?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 3/5       |
| Completeness  | 5/5       | 3/5       |
| Accuracy      | 4/5       | 3/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 5/5       | 3/5       |
| **Total**     | **20/25** | **16/25** |

**Winner**: Pith
**Notes**: Pith won on completeness and actionability, providing all 9 dependent files via importedBy edges. Control missed src/cli/index.ts due to multi-line imports.

---

#### R2: API to Database

**Question**: "How do the API routes connect to the database layer?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **16/25** | **24/25** |

**Winner**: Control
**Notes**: Pith provided verbose output but missed the critical initialization flow (getDb() → createApp()). Control found complete connection pattern.

---

#### R3: extractFile Consumers

**Question**: "What are all the consumers of the extractFile function?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **14/25** | **24/25** |

**Winner**: Control
**Notes**: Pith showed 13 files with importedBy edges but couldn't distinguish which actually use extractFile. Control found exactly 4 files that import/call extractFile.

---

### Debugging Tasks (D1-D3)

#### D1: Empty Prose

**Question**: "Generation completes but some nodes have empty prose. What should I investigate?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 5/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 3/5       | 5/5       |
| Actionability | 5/5       | 4/5       |
| **Total**     | **22/25** | **23/25** |

**Winner**: Control
**Notes**: Control wins narrowly due to efficiency (8.7k vs 20.3k tokens). Both identified all critical debugging locations.

---

#### D2: Slow Generation

**Question**: "Why might the generate command be slow?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 4/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 4/5       | 3/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **19/25** | **23/25** |

**Winner**: Control
**Notes**: Pith missed the main slowness cause: sequential processing with no parallelization. Control found the for-loop pattern and contrast with extract's BATCH_SIZE=4.

---

#### D3: 404 for Existing File

**Question**: "API returns 404 for a file that exists. What could cause this?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 2/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 1/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **13/25** | **25/25** |

**Winner**: Control
**Notes**: Pith returned 19k tokens with ~10% relevant content. Control used 2.5k tokens to find exact 404 logic, path parsing, and all possible causes.

---

### Modification Tasks (M1-M3)

#### M1: JavaScript Support

**Question**: "How would I add support for JavaScript (.js) files in addition to TypeScript?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 2/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 1/5       | 5/5       |
| Actionability | 2/5       | 5/5       |
| **Total**     | **13/25** | **25/25** |

**Winner**: Control
**Notes**: Control found all 5 modification points with precise line numbers. Pith missed critical line 380 hardcoded .ts check and used 10x more tokens.

---

#### M2: Rate Limiting

**Question**: "How would I add rate limiting to the API endpoints?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 2/5       | 4/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 4/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **15/25** | **23/25** |

**Winner**: Control
**Notes**: Pith provided only src/api/index.ts (19k tokens) missing package.json and CLI context. Control gathered 3 relevant files more efficiently.

---

#### M3: Add Complexity Field

**Question**: "I want to add a 'complexity' field to WikiNode. What files need changes?"

| Criterion     | Pith      | Control   |
| ------------- | --------- | --------- |
| Relevance     | 3/5       | 5/5       |
| Completeness  | 3/5       | 5/5       |
| Accuracy      | 5/5       | 5/5       |
| Efficiency    | 2/5       | 5/5       |
| Actionability | 3/5       | 5/5       |
| **Total**     | **16/25** | **25/25** |

**Winner**: Control
**Notes**: Pith provided importedBy edges but included 25+ function signatures (21k tokens). Control found exact modification points with 7x fewer tokens.

---

## Summary

### Overall Scores

| Metric            | Pith                | Control             |
| ----------------- | ------------------- | ------------------- |
| **Average score** | **16.8/25 (67.2%)** | **23.3/25 (93.3%)** |
| Win/Loss/Tie      | 1-13-1              | 13-1-1              |

### Score Breakdown by Category

| Category             | Pith Avg | Control Avg | Gap  |
| -------------------- | -------- | ----------- | ---- |
| Architecture (A1-A3) | 15.3     | 23.0        | -7.7 |
| Behavior (B1-B3)     | 19.3     | 24.3        | -5.0 |
| Relationship (R1-R3) | 16.7     | 21.3        | -4.6 |
| Debugging (D1-D3)    | 18.0     | 23.7        | -5.7 |
| Modification (M1-M3) | 14.7     | 24.3        | -9.6 |

### Score Breakdown by Criterion

| Criterion     | Pith Avg | Control Avg | Gap  |
| ------------- | -------- | ----------- | ---- |
| Relevance     | 3.1      | 4.9         | -1.8 |
| Completeness  | 3.3      | 4.7         | -1.4 |
| Accuracy      | 4.7      | 4.9         | -0.2 |
| Efficiency    | 2.4      | 4.4         | -2.0 |
| Actionability | 3.1      | 4.7         | -1.6 |

### Comparison to Previous Benchmarks

| Metric          | v1 (2025-12-31) | This Run (v2) | Change   |
| --------------- | --------------- | ------------- | -------- |
| Pith Average    | 19.4/25 (78%)   | 16.8/25 (67%) | **-11%** |
| Control Average | 22.9/25 (92%)   | 23.3/25 (93%) | +1%      |
| Gap             | -3.5 points     | -6.5 points   | -3.0     |
| Pith Win Rate   | 5-9-1           | 1-13-1        | -4 wins  |

---

## Information Gap Analysis

### Critical Issues Identified

| Issue                          | Impact | Examples                                                                            |
| ------------------------------ | ------ | ----------------------------------------------------------------------------------- |
| **Path mismatch**              | High   | A2, A3: API couldn't find files with incorrect paths (src/extract vs src/extractor) |
| **Token inefficiency**         | High   | B2, B3, D3: 8-10x more tokens than needed for focused questions                     |
| **File-level vs symbol-level** | High   | R3: importedBy shows 13 files but only 4 actually use extractFile                   |
| **Missing cross-file context** | Medium | R2, M2: Didn't show how files connect (getDb→createApp flow)                        |

### Pith Advantages (When Working)

| Information Type          | Pith  | Control | Notes                         |
| ------------------------- | ----- | ------- | ----------------------------- |
| Pre-computed dependencies | ✅    | ⚠️      | R1: Won with importedBy edges |
| Structured metadata       | ✅    | ⚠️      | Consistent format             |
| Accuracy                  | 4.7/5 | 4.9/5   | Both high accuracy            |

### Control Advantages

| Information Type      |     Pith      |   Control    | Gap Severity |
| --------------------- | :-----------: | :----------: | :----------: |
| Efficiency            |     2.4/5     |    4.4/5     | **Critical** |
| Targeted searches     |      ❌       |      ✅      |     High     |
| Symbol-level tracking | ⚠️ File-level |  ✅ Precise  |     High     |
| Cross-file flows      |  ⚠️ Isolated  | ✅ Connected |     High     |
| Line number precision | ⚠️ Sometimes  |  ✅ Always   |    Medium    |

---

## Key Conclusions

### 1. Regression from v1

- Pith average: 78% → **67%** (-11%)
- Win rate: 5 wins → **1 win**
- Gap widened from 3.5 to 6.5 points

### 2. Root Causes

1. **Path sensitivity**: API queries with incorrect file paths returned nothing useful (A2, A3)
2. **Verbose responses**: Full file dumps when targeted info needed (B2, B3, D3, M1-M3)
3. **File-level granularity**: Can't distinguish symbol-level imports (R3)

### 3. Pith's Only Win

- **R1 (WikiNode Impact)**: importedBy edges provided complete dependency list immediately

### 4. Control's Consistent Strengths

- Targeted searches with grep/glob
- Symbol-level precision
- Cross-file flow tracing
- Efficient token usage

---

## Recommendations

### For Pith Development (Priority Order)

1. **Critical - Query resilience**: Suggest correct paths when nodes not found
2. **Critical - Response sizing**: Return focused excerpts, not full files
3. **High - Symbol tracking**: Track which symbols are used, not just file imports
4. **High - Cross-file context**: Include related files in context bundles
5. **Medium - Path normalization**: Handle various path formats consistently

### For Usage

1. **Use Pith for**: Dependency impact analysis (R1-type queries)
2. **Use Control for**: Everything else until improvements are made
3. **Verify paths**: Ensure exact file paths match extracted nodes

---

## Revision History

| Date       | Change           | Author |
| ---------- | ---------------- | ------ |
| 2025-12-31 | v2 benchmark run | Claude |
