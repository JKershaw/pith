# Benchmark Plan: 2026-01-01

## Repository

- **Target**: Pith (self-test)
- **Pith version**: b94ab85
- **Size**: ~34 source files, ~20k lines of TypeScript
- **Model**: qwen/qwen-turbo (configured in environment)

## Tasks

Running the **full 15-task bank** from BENCHMARKING.md:

### Architecture Tasks (A1-A3)

- A1: "What are the main components of this codebase and how do they interact?"
- A2: "Explain the data flow from file input to wiki output."
- A3: "What design patterns are used in this codebase?"

### Specific Behavior Tasks (B1-B3)

- B1: "How does the extraction cache determine if a file needs re-extraction?"
- B2: "How does buildPrompt construct LLM prompts for different node types?"
- B3: "What is the retry logic in the LLM client and what triggers a retry?"

### Relationship Tasks (R1-R3)

- R1: "What files would be affected if I changed the WikiNode interface?"
- R2: "How do the API routes connect to the database layer?"
- R3: "What are all the consumers of the extractFile function?"

### Debugging Tasks (D1-D3)

- D1: "Generation completes but some nodes have empty prose. What should I investigate?"
- D2: "Why might the generate command be slow?"
- D3: "API returns 404 for a file that exists. What could cause this?"

### Modification Tasks (M1-M3)

- M1: "How would I add support for JavaScript (.js) files in addition to TypeScript?"
- M2: "How would I add rate limiting to the API endpoints?"
- M3: "I want to add a 'complexity' field to WikiNode. What files need changes?"

## Estimates

- **Extraction**: ~10-15s (based on previous runs with similar size)
- **Build**: ~3s
- **Generation**: ~3-4 minutes
- **Task evaluation**: ~20-30 minutes (15 tasks × 2 approaches each)
- **Total duration**: ~35-45 minutes

### Cost Estimate

- Generation: ~$0.50-1.00 (qwen-turbo, ~150 nodes)
- Control agent exploration: ~$0.50-1.00 (15 tasks × exploration calls)
- **Total estimated cost**: ~$1.00-2.00

## Methodology

1. Run full Pith pipeline (extract → build → generate) with timing
2. For each task:
   - Query Pith API for relevant context
   - Run Control agent (2-min time limit, grep/glob/read tools)
   - Judge both contexts using the scoring rubric
3. Compare results with previous benchmarks (2025-12-31-self-test-v4.md, 2025-12-30-self-test-v7.md)

## Success Criteria

- Complete all 15 tasks
- Capture timing for each pipeline stage
- Score each approach on all 5 criteria
- Identify improvements or regressions from previous runs
