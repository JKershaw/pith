# Benchmark Run: 2025-12-30 (Second Run)

## Configuration

- **Repository**: Pith (self-test)
- **Size**: 24 files, ~10.5k lines
- **Pith version**: c61a6e8
- **Model**: qwen/qwen-turbo

## Pipeline Metrics

| Stage | Time | Notes |
|-------|------|-------|
| Extraction | 7.4s | 29 files extracted |
| Build | 0.9s | 96 nodes created |
| Generation | 123.1s | 39 nodes with prose |
| **Total** | ~132s | |

- Nodes created: 29 file, 57 function, 10 module (96 total)
- Nodes with prose: 39 (files + modules only)
- Estimated cost: ~$0.50-1.00 (qwen-turbo pricing)

## Task Results

### Task 1: Architecture
**Question**: "Explain the three-stage pipeline (extract, build, generate) and data flow between stages"

| Criterion | Pith | Control |
|-----------|------|---------|
| Relevance | 3 | 5 |
| Completeness | 2 | 5 |
| Accuracy | 4 | 5 |
| Efficiency | 4 | 4 |
| Actionability | 2 | 5 |
| **Total** | 15/25 | 24/25 |

- **Winner**: Control
- **Pith tokens**: ~1,500 (4 modules + key files)
- **Control tokens**: ~4,000 (comprehensive exploration)
- **Notes**: Pith provided module-level summaries with generic quick-start examples but no actual data flow explanation. Control traced the complete flow from ExtractedFile → WikiNode → ProseData with specific interfaces, line numbers (e.g., lines 99-109 for ExtractedFile, lines 37-70 for WikiNode), and database collections.

---

### Task 2: Specific Behavior
**Question**: "How does the AST extractor handle different TypeScript node types (functions, classes, interfaces)?"

| Criterion | Pith | Control |
|-----------|------|---------|
| Relevance | 3 | 5 |
| Completeness | 2 | 5 |
| Accuracy | 4 | 5 |
| Efficiency | 4 | 4 |
| Actionability | 2 | 5 |
| **Total** | 15/25 | 24/25 |

- **Winner**: Control
- **Pith tokens**: ~800
- **Control tokens**: ~3,500
- **Notes**: Pith showed function signatures and mentioned "ts-morph" in gotchas. Control provided exact line numbers for each extraction type (functions: 434-451, classes: 453-481, interfaces: 483-492), code snippets showing the actual extraction logic, and detailed breakdown of KeyStatement categories (config, url, math, condition, error).

---

### Task 3: Cross-Module Relationship
**Question**: "Trace how a WikiNode flows from creation in extractor to output in generator"

| Criterion | Pith | Control |
|-----------|------|---------|
| Relevance | 3 | 5 |
| Completeness | 2 | 5 |
| Accuracy | 4 | 5 |
| Efficiency | 3 | 4 |
| Actionability | 2 | 5 |
| **Total** | 14/25 | 24/25 |

- **Winner**: Control
- **Pith tokens**: ~2,000 (3 modules + key files)
- **Control tokens**: ~5,000
- **Notes**: Pith described each module's purpose separately but didn't trace the actual data flow or transformations. Control provided a complete flow diagram showing: (1) ExtractedFile creation in ast.ts, (2) WikiNode building in builder/index.ts with specific functions (buildFileNode at lines 77-141), (3) ProseData generation at lines 581-604, (4) API output formatting at lines 105-269.

---

### Task 4: Debugging
**Question**: "Generation fails with 'invalid model' error. What files and logic should I investigate?"

| Criterion | Pith | Control |
|-----------|------|---------|
| Relevance | 2 | 5 |
| Completeness | 2 | 5 |
| Accuracy | 3 | 5 |
| Efficiency | 2 | 5 |
| Actionability | 2 | 5 |
| **Total** | 11/25 | 25/25 |

- **Winner**: Control
- **Pith tokens**: ~2,500
- **Control tokens**: ~3,000
- **Notes**: Pith provided module descriptions with generic gotchas like "error handling may need extending." Control identified: (1) exact model configuration sources (CLI line 480, env var, config), (2) model validation gap (no pre-validation before API call), (3) error handling logic at lines 515-534, (4) retry logic at lines 442-461 showing 400 errors don't retry. Created a debugging checklist with specific commands and example error messages.

---

### Task 5: Modification
**Question**: "I want to add Python support. What architectural changes are needed?"

| Criterion | Pith | Control |
|-----------|------|---------|
| Relevance | 2 | 5 |
| Completeness | 1 | 5 |
| Accuracy | 3 | 5 |
| Efficiency | 1 | 5 |
| Actionability | 1 | 5 |
| **Total** | 8/25 | 25/25 |

- **Winner**: Control
- **Pith tokens**: ~1,500
- **Control tokens**: ~4,500
- **Notes**: Pith only described module purposes with no actionable Python support information. Control identified: (1) all TypeScript-specific locations (lines 241, 242, 256, 291), (2) language-agnostic components that need no changes (git, builder, generator, API), (3) 5-phase implementation plan, (4) parser alternatives (tree-sitter vs pyright vs subprocess), (5) file-by-file change severity table, (6) example config for Python projects.

---

## Summary

| Metric | Pith | Control |
|--------|------|---------|
| Average score | 12.6/25 | 24.4/25 |
| Win/Loss/Tie | 0-5-0 | 5-0-0 |

### Score Breakdown by Criterion

| Criterion | Pith Avg | Control Avg |
|-----------|----------|-------------|
| Relevance | 2.6 | 5.0 |
| Completeness | 1.8 | 5.0 |
| Accuracy | 3.6 | 5.0 |
| Efficiency | 2.8 | 4.4 |
| Actionability | 1.8 | 5.0 |

### Comparison to Previous Run

| Metric | Previous | Current | Change |
|--------|----------|---------|--------|
| Pith Average | 12.6/25 | 12.6/25 | No change |
| Control Average | 24.2/25 | 24.4/25 | +0.2 |
| Pith Completeness | 1.8/5 | 1.8/5 | No change |
| Pith Actionability | 1.8/5 | 1.8/5 | No change |

**Conclusion**: Results are consistent with the previous benchmark run. No improvements detected since the same version was tested.

---

## Information Gap Analysis

### Information Type Comparison

| Information Type | Pith | Control | Gap Severity |
|------------------|:----:|:-------:|:------------:|
| Module/file names | ✅ | ✅ | None |
| One-line summary | ✅ | ✅ | None |
| Purpose description | ✅ | ✅ | Minor |
| Gotchas/warnings | ⚠️ Vague | ✅ Specific | **High** |
| Key exports list | ✅ | ✅ | None |
| Import relationships | ✅ | ✅ | Minor |
| Fan-in/fan-out metrics | ✅ | ❌ | None (Pith advantage) |
| Git metadata | ✅ | ❌ | None (Pith advantage) |
| **Line numbers** | ✅ New! | ✅ | Improved but still gap |
| **Code snippets** | ✅ New! | ✅ | Improved but still gap |
| **Function signatures** | ✅ | ✅ | Minor |
| Specific variable/config values | ❌ | ✅ | **High** |
| Implementation details | ❌ | ✅ | **Critical** |
| Error handling logic | ❌ | ✅ | **High** |
| Data flow explanation | ❌ | ✅ | **High** |
| Priority/criticality ranking | ❌ | ✅ | Medium |
| Test file locations | ✅ | ✅ | None |
| Suggested changes | ❌ | ✅ | **High** |

### Notable Improvements Since Phase 6.6

Pith now includes:
- Function line numbers in context output (e.g., "lines 131-141")
- Code snippets (first 15 lines with truncation)
- Key statements with categories and line numbers

However, these improvements don't yet translate to better task scores because:
1. **Prose doesn't reference them**: The LLM-generated summaries don't incorporate the new line numbers and snippets
2. **No synthesis**: Raw data is present but not synthesized into actionable guidance
3. **Missing cross-references**: Data flow between files isn't explained

### Concrete Example: Task 2 (AST Handling)

| Detail | Pith Said | Control Said | Gap |
|--------|-----------|--------------|-----|
| Function extraction location | Listed `extractKeyStatements` function | "Functions extracted at lines 434-451 using `sourceFile.getFunctions()`" | **Context missing** |
| Class extraction | Not specifically mentioned | "Classes at lines 453-481, methods use same FunctionData structure" | **Missing entirely** |
| Interface extraction | Not specifically mentioned | "Interfaces at lines 483-492, simpler (no methods)" | **Missing entirely** |
| Key statement categories | Listed function but no explanation | "5 categories: config, url, math, condition, error (lines 149-231)" | **Detail missing** |

### Concrete Example: Task 4 (Debugging)

| Detail | Pith Said | Control Said | Gap |
|--------|-----------|--------------|-----|
| Model source | "set in .env or CLI option" | "Priority: CLI → env var → config → default (line 480)" | **Specifics missing** |
| Validation | "may need extending" | "No pre-validation, only validated when API rejects (400)" | **Critical insight missing** |
| Retry behavior | Not mentioned | "400 errors don't retry (lines 442-461), throws immediately" | **Missing entirely** |
| Error message format | Not mentioned | "Error includes OpenRouter response in errorText" | **Missing entirely** |

---

## Key Observations

### Pith's Strengths
1. **Accuracy** remains reasonable (3.6/5) - prose is factually correct
2. **New Phase 6.6.1 data** - line numbers and code snippets now in raw data
3. **Fast retrieval** - context returned in milliseconds once wiki built
4. **Consistent** - reproducible results across benchmark runs

### Pith's Persistent Weaknesses
1. **Prose-data disconnect**: Generated prose doesn't reference line numbers or code snippets
2. **No implementation synthesis**: Can't explain how pieces connect
3. **Vague gotchas**: "may need extending" vs "400 errors don't retry at line 533"
4. **No cross-file tracing**: Can't follow data flow across modules

### Recommendations for Next Phase

1. **Feed deterministic data to LLM prompts**: Include line numbers and code snippets in prose generation prompts
2. **Add data flow prompts for modules**: Ask LLM to explain how child files connect
3. **Enhance gotcha generation**: Include specific line numbers and values in gotcha warnings
4. **Add debugging-specific queries**: Build prompts that identify error handling patterns

---

## Revision History

| Date | Change | Author |
|------|--------|--------|
| 2025-12-30 | Second benchmark run with new tasks | Claude |
