# Benchmark Plan: 2025-12-30 Self-Test v3

## Repository

- **Target**: Pith (self-test)
- **Location**: `/home/user/pith`
- **Size**: ~24 TypeScript files, ~10.5k lines
- **Commit**: d2240b9 (after merging PR #15 with improved LLM prompts)

## Purpose

Third benchmark run to assess improvements from Phase 6.7 changes (improved LLM prompts requesting actionable details). This follows PR #15 merge which included prompt enhancements.

## Tasks Selected

| # | Category | Task |
|---|----------|------|
| 1 | Architecture | "How do the CLI commands (extract, build, generate) orchestrate the pipeline stages?" |
| 2 | Specific Behavior | "What is the retry logic in the LLM client and what triggers a retry?" |
| 3 | Cross-module | "How does data flow from AST extraction through to the final wiki output?" |
| 4 | Debugging | "Build command completes but some nodes have no prose. What could cause this?" |
| 5 | Modification | "I want to add support for extracting JSDoc comments. What files need changes?" |

## Task Selection Rationale

- **Task 1**: Tests CLI orchestration understanding - different angle from previous runs
- **Task 2**: Tests specific implementation detail extraction - critical for actionability
- **Task 3**: Tests end-to-end data flow tracing
- **Task 4**: New debugging scenario (partial generation failure)
- **Task 5**: Focused modification task (JSDoc support)

## Expected Duration

| Stage | Estimated Time |
|-------|---------------|
| Extraction | ~8s |
| Build | ~1s |
| Generation | ~2 min |
| Task Evaluation (5 tasks Ã— 2 agents) | ~10 min |
| **Total** | ~15 min |

## Estimated Cost

- Generation: ~$0.50-1.00 (qwen-turbo)
- Task evaluation: ~$0.20 (5 tasks, judge calls)
- **Total**: ~$1.00-1.50

## Comparison Baseline

Previous run (2025-12-30-self-test-v2.md):
- Pith average: 12.6/25
- Control average: 24.4/25
- Win/Loss/Tie: 0-5-0

Key gap areas to watch:
- Implementation details (was Critical gap)
- Line numbers (was High gap)
- Error handling logic (was High gap)
