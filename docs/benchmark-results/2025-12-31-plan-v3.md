# Benchmark Plan: 2025-12-31-v3

## Configuration

- **Repository**: Pith (self-test)
- **Size**: 34 TypeScript files, ~18k lines
- **Pith version**: c536fba
- **Model**: qwen/qwen-turbo (default)
- **Tasks**: All 15 tasks (full task bank)

## Test Repository Justification

Using Pith itself as the test repository:

- TypeScript codebase (Pith's target scope)
- Meaningful git history with recent development
- Well-understood architecture for validation
- Quick regression test size (<20k lines)

## Tasks to Evaluate

### Architecture Tasks (A1-A3)

- A1: "What are the main components of this codebase and how do they interact?"
- A2: "Explain the data flow from file input to wiki output."
- A3: "What design patterns are used in this codebase?"

### Specific Behavior Tasks (B1-B3)

- B1: "How does the extraction cache determine if a file needs re-extraction?"
- B2: "How does buildPrompt construct LLM prompts for different node types?"
- B3: "What is the retry logic in the LLM client and what triggers a retry?"

### Relationship Tasks (R1-R3)

- R1: "What files would be affected if I changed the WikiNode interface?"
- R2: "How do the API routes connect to the database layer?"
- R3: "What are all the consumers of the extractFile function?"

### Debugging Tasks (D1-D3)

- D1: "Generation completes but some nodes have empty prose. What should I investigate?"
- D2: "Why might the generate command be slow?"
- D3: "API returns 404 for a file that exists. What could cause this?"

### Modification Tasks (M1-M3)

- M1: "How would I add support for JavaScript (.js) files in addition to TypeScript?"
- M2: "How would I add rate limiting to the API endpoints?"
- M3: "I want to add a 'complexity' field to WikiNode. What files need changes?"

## Expected Duration and Cost

Based on previous runs (v2, v3):

| Stage               | Expected Time | Notes                        |
| ------------------- | ------------- | ---------------------------- |
| Extraction          | ~15s          | 34 files                     |
| Build               | ~5s           | ~150 nodes expected          |
| Generation          | ~4 min        | ~50 nodes with prose         |
| **Pipeline Total**  | ~5 min        |                              |
| Task Evaluation     | ~30 min       | 15 tasks Ã— 2 approaches each |
| **Total Benchmark** | ~35 min       |                              |

**Estimated Cost**:

- Generation: ~$0.50-1.00 (qwen-turbo)
- Task evaluation: Included in benchmark execution

## Previous Benchmark Summary

| Metric          | v2 (2025-12-31) | v3 (2025-12-31) |
| --------------- | --------------- | --------------- |
| Pith Average    | 16.8/25 (67%)   | 16.3/25 (65%)   |
| Control Average | 23.3/25 (93%)   | 24.5/25 (98%)   |
| Gap             | -6.5 points     | -8.2 points     |
| Pith Win Rate   | 1-13-1          | 0-15-0          |

## Goals

1. Establish current baseline after recent code changes (commit c536fba)
2. Measure pipeline performance metrics
3. Compare Pith vs Control across all 15 task types
4. Identify any improvements or regressions from previous benchmarks
